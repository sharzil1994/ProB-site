{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85795f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 14:07:02.900806: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-27 14:07:02.943579: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 14:07:02.943619: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 14:07:02.943659: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 14:07:02.953049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar 14 17:05:30 2022\n",
    "\n",
    "@author: haris\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# from Bio import SeqIO\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, MaxPooling1D,LayerNormalization, Dropout, Flatten, Dense, concatenate \n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.metrics import binary_accuracy\n",
    "# from keras import regularizers\n",
    "# import matplotlib.pyplot as plt\n",
    "#from group_norm import GroupNormalization\n",
    "from sklearn.metrics import confusion_matrix, recall_score, roc_curve, roc_auc_score, auc, average_precision_score\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "import random\n",
    "# import scikitplot as skplt\n",
    "# import seaborn as sn\n",
    "import itertools\n",
    "import pickle\n",
    "np.random.seed(seed=21)\n",
    "# ************ Data Processing ****************\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "# from des_extraction import *\n",
    "from feature_extraction import *\n",
    "\n",
    "model_num=1                   # change\n",
    "folder_num=14\n",
    "# w_size=23\n",
    "\n",
    "\n",
    "f_name=str(folder_num)\n",
    "\n",
    "l= os.listdir('./')\n",
    "skip=False\n",
    "for list in l:\n",
    "    if list =='results_'+f_name:\n",
    "        skip=True\n",
    "if skip==False:\n",
    "    os.mkdir( 'results_'+f_name)\n",
    "\n",
    "OutputDir = f'./results_{f_name}'\n",
    "\n",
    "\n",
    "file = open(OutputDir + '/performance_ind.txt', 'w')\n",
    "\n",
    "\n",
    "w_size=19\n",
    "# for w_size in a1 :\n",
    "list_1=l= os.listdir('./descriptor')\n",
    "skip=False\n",
    "for index_0 in list_1:\n",
    "    if index_0 ==f'./descriptor/in_x_pssm_{w_size}.dat':\n",
    "        skip=True\n",
    "if skip==False:\n",
    "    feature_extraction(w_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def listToString(s):  \n",
    "\n",
    "    str1 = \"\"  \n",
    "    \n",
    "    # traverse in the string   \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "    \n",
    "    # return string   \n",
    "    return str1   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepareData():\n",
    "\n",
    "    feature1 = pickle.load(open(f'./descriptor/train_x_pssm_{w_size}.dat',\"rb\"))\n",
    "    feature2 = pickle.load(open(f'./descriptor/train_x_dssp_{w_size}.dat',\"rb\"))\n",
    "    feature3 = pickle.load(open(f'./descriptor/train_x_hmm_{w_size}.dat',\"rb\"));\n",
    "       \n",
    "\n",
    "    label = pickle.load(open(f'./descriptor/train_y_{w_size}.dat',\"rb\"))\n",
    "\n",
    "    \n",
    "    return feature1,feature2,feature3, label\n",
    "\n",
    "\n",
    "\n",
    "def funciton(PositiveCSV, NegativeCSV, OutputDir, folds):\n",
    "\n",
    "    Positive_X, Positive_y, Negative_X, Negative_y = prepareData(PositiveCSV, NegativeCSV)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculateScore(X,XX,XXX, y, model, folds):\n",
    "    \n",
    "    score = model.evaluate([X,XX,XXX], y) # Gives loss and accuracy\n",
    "    pred_y = model.predict([X,XX,XXX])\n",
    "\n",
    "    accuracy = score[1];\n",
    "    \n",
    "    \n",
    "    global acc1\n",
    "    acc1=accuracy\n",
    "    \n",
    "\n",
    "    tempLabel = np.zeros(shape = y.shape, dtype=np.int32)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if pred_y[i] < 0.5:\n",
    "            tempLabel[i] = 0;\n",
    "        else:\n",
    "            tempLabel[i] = 1;\n",
    "    # print(tempLabel)        \n",
    "    \n",
    "    confusion = confusion_matrix(y, tempLabel)\n",
    "    TN, FP, FN, TP = confusion.ravel()\n",
    "\n",
    " \n",
    "    sensitivity = TP / float(TP + FN)\n",
    "    specificity = TN / float(TN + FP)\n",
    "    from sklearn.metrics import matthews_corrcoef\n",
    "    MCC=matthews_corrcoef(y, tempLabel)\n",
    "    \n",
    "    F1Score = (2 * TP) / float(2 * TP + FP + FN)\n",
    "    precision = TP / float(TP + FP)\n",
    "\n",
    "    pred_y = pred_y.reshape((-1, ))\n",
    "\n",
    "    ROCArea = roc_auc_score(y, pred_y)\n",
    "    AUPRC   = average_precision_score(y, pred_y)\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred_y)\n",
    "    lossValue = None;\n",
    "\n",
    "    print(y.shape)\n",
    "    print(pred_y.shape)\n",
    "\n",
    "    y_true = tf.convert_to_tensor(y, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(pred_y, np.float32)\n",
    "    \n",
    "    # plt.show() \n",
    "    \n",
    "    lossValue = losses.binary_crossentropy(y_true, y_pred)#.eval()\n",
    "\n",
    "    return {'sn' : sensitivity, 'sp' : specificity, 'acc' : accuracy, 'MCC' : MCC, 'AUC' : ROCArea,'AUPRC' : AUPRC, 'precision' : precision, 'F1' : F1Score}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "\n",
    "TF_ENABLE_ONEDNN_OPTS=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### indepentend dataset test_60.. descriptor  and labels###############\n",
    "in_X_pssm=pickle.load(open(f'./descriptor/in_x_pssm_{w_size}.dat',\"rb\"))\n",
    "in_X_dssp=pickle.load(open(f'./descriptor/in_x_dssp_{w_size}.dat',\"rb\"))\n",
    "in_X_hmm=pickle.load(open(f'./descriptor/in_x_hmm_{w_size}.dat',\"rb\"))\n",
    "in_y=pickle.load(open(f'./descriptor/in_y_{w_size}.dat',\"rb\")) # label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb6b221-c42f-4e3b-abdb-440b23c10480",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def shuffleData(X, y, z):\n",
    "    index = [i for i in range(len(X))]\n",
    "    random.shuffle(index)\n",
    "    X = X[index]\n",
    "    y = y[index]\n",
    "    z = z[index]\n",
    "    return X, y ,z;\n",
    "\n",
    "\n",
    "def shuffleData2(X1,X2,X3, y):\n",
    "    index = [i for i in range(len(X1))]\n",
    "    random.shuffle(index)\n",
    "    X1 = X1[index]\n",
    "    X2 = X2[index]\n",
    "    X3 = X3[index]\n",
    "    y = y[index]\n",
    "    return X1, X2,X3, y;\n",
    "\n",
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 0.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "#### model no 1 change\n",
    "def model_cnn(w_size):\n",
    "    \n",
    "    input_shape = (w_size,20) # One Hot\n",
    "    inputs = Input(shape = input_shape)\n",
    "    inputs2 = Input(shape = (w_size,14))  #NCPD\n",
    "    inputs3 = Input(shape = (w_size,20))  #EIIP\n",
    "\n",
    "    initializer = tf.keras.initializers.RandomUniform(seed=23)\n",
    "    c1 = Conv1D(64,5, strides=1, activation='relu', input_shape=(w_size, 20))(inputs)\n",
    "    c1 = Conv1D(32,3, strides=1, activation='relu')(c1)\n",
    "    c1 = Conv1D(16,3, strides=1, activation='relu')(c1)\n",
    "\n",
    "    c1 = LayerNormalization()(c1)\n",
    "    # c1 = BatchNormalization()(c1)\n",
    "    #c1 = MaxPooling1D(2,strides=3)(c1)\n",
    "    c1 = Dropout(0.1,seed = 21)(c1)     # originally 0.1\n",
    "\n",
    "\n",
    "    c2 = Conv1D(64,5, strides=1, activation='relu', input_shape=(w_size, 14))(inputs2)\n",
    "    c2 = Conv1D(32,3, strides=1, activation='relu')(c2)\n",
    "    c2 = Conv1D(16,3, strides=1, activation='relu')(c2)\n",
    "\n",
    "    c2 = LayerNormalization()(c2)\n",
    "    # c2 = BatchNormalization()(c2)\n",
    "    #c2 = MaxPooling1D(2,strides=3)(c2)\n",
    "    c2 = Dropout(0.3,seed = 21)(c2)    # originally 0.3\n",
    "\n",
    "    c3 = Conv1D(64,5, strides=1, activation='relu', input_shape=(w_size, 20))(inputs3)\n",
    "    c3 = Conv1D(32,3, strides=1, activation='relu')(c3)\n",
    "    c3 = Conv1D(16,3, strides=1, activation='relu')(c3)\n",
    "\n",
    "    c3 = LayerNormalization()(c3)\n",
    "    \n",
    "    # c3 = BatchNormalization()(c3)\n",
    "    c3 = Dropout(0.2,seed = 21)(c3)   # originally 0.2\n",
    "\n",
    "    # con0 = concatenate([c1,c2,c3])\n",
    "    con0 = concatenate([c1,c2,c3])\n",
    "\n",
    "    # cd = Dropout(0.20)(con0)\n",
    "  \n",
    "\n",
    "    # fc = Flatten()(cd)\n",
    "\n",
    "    fc = Flatten()(con0)\n",
    "\n",
    "    fc1 = Dense(256, activation='relu')(fc)\n",
    "    #cd = Dropout(0.10)(fc1)\n",
    "\n",
    "    fc1 = Dense(128, activation='relu')(fc1)\n",
    "\n",
    "    fc1 = Dense(64, activation='relu')(fc1)\n",
    "    \n",
    "    fc2 = Dense(1, activation='sigmoid')(fc1)\n",
    "    \n",
    "    #model1 = Model(inputs =[ip], outputs = [fc2])\n",
    "    \n",
    "    #model1.compile(loss='kl_divergence', optimizer= 'adam', metrics=['accuracy'])\n",
    "    model1 = Model(inputs =[inputs,inputs2,inputs3], outputs = [fc2])    \n",
    "    opt=SGD(learning_rate=0.003, momentum = 0.99)\n",
    "\n",
    "    model1.compile(loss='binary_crossentropy', optimizer= opt, metrics=['accuracy'])\n",
    "    \n",
    "    return model1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.utils import compute_class_weight\n",
    "train_1,train_2,train_3, train_label = prepareData()\n",
    "\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "for index in train_label:\n",
    "    if index==1:\n",
    "        i=i+1\n",
    "    if index==0:\n",
    "        j=j+1\n",
    "    k=k+1      \n",
    "    \n",
    "\n",
    "positive_train_1 = np.zeros((i, w_size, 20))\n",
    "positive_train_2 = np.zeros((i, w_size, 14))\n",
    "positive_train_3 = np.zeros((i, w_size, 20))\n",
    "\n",
    "negative_train_1= np.zeros((j, w_size, 20))\n",
    "negative_train_2 = np.zeros((j, w_size, 14))\n",
    "negative_train_3 = np.zeros((j, w_size, 20))\n",
    "\n",
    "positive_train_label = np.zeros((i,))\n",
    "negative_train_label = np.zeros((j,))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "for index in train_label:\n",
    "    if index==1:\n",
    "        positive_train_label[i]=index\n",
    "        positive_train_1[i]=train_1[k]\n",
    "        positive_train_2[i]=train_2[k]\n",
    "        positive_train_3[i]=train_3[k]        \n",
    "        i=i+1\n",
    "    if index==0:\n",
    "        negative_train_label[j]=index\n",
    "        negative_train_1[j]=train_1[k]\n",
    "        negative_train_2[j]=train_2[k]\n",
    "        negative_train_3[j]=train_3[k]\n",
    "        \n",
    "        j=j+1\n",
    "\n",
    "    k=k+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2109352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 16:55:14.133260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 65692 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:1d:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 16:55:18.696012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-02-26 16:55:19.388893: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-26 16:55:19.525986: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-26 16:55:21.315326: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f544c19e230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-26 16:55:21.315366: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-02-26 16:55:21.423665: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 19s 19ms/step - loss: 0.6943 - accuracy: 0.4948 - val_loss: 0.6868 - val_accuracy: 0.5998\n",
      "Epoch 2/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6752 - accuracy: 0.5368 - val_loss: 0.6630 - val_accuracy: 0.6213\n",
      "Epoch 3/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6629 - accuracy: 0.5564 - val_loss: 0.5987 - val_accuracy: 0.6641\n",
      "Epoch 4/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6492 - accuracy: 0.5613 - val_loss: 0.5160 - val_accuracy: 0.7438\n",
      "Epoch 5/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6419 - accuracy: 0.5675 - val_loss: 0.7380 - val_accuracy: 0.5654\n",
      "Epoch 6/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6386 - accuracy: 0.5571 - val_loss: 0.5431 - val_accuracy: 0.7159\n",
      "Epoch 7/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6370 - accuracy: 0.5440 - val_loss: 0.5983 - val_accuracy: 0.6546\n",
      "Epoch 8/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6335 - accuracy: 0.5519 - val_loss: 0.6133 - val_accuracy: 0.5283\n",
      "Epoch 9/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6195 - accuracy: 0.5521 - val_loss: 0.5774 - val_accuracy: 0.5918\n",
      "Epoch 10/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6193 - accuracy: 0.5459 - val_loss: 0.6441 - val_accuracy: 0.6460\n",
      "Epoch 11/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6003 - accuracy: 0.6284 - val_loss: 0.5577 - val_accuracy: 0.6827\n",
      "Epoch 12/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6052 - accuracy: 0.6011 - val_loss: 0.5919 - val_accuracy: 0.5593\n",
      "Epoch 13/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5870 - accuracy: 0.6343 - val_loss: 0.5065 - val_accuracy: 0.7184\n",
      "Epoch 14/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5858 - accuracy: 0.6355 - val_loss: 0.6308 - val_accuracy: 0.5424\n",
      "Epoch 15/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5744 - accuracy: 0.6475 - val_loss: 0.5894 - val_accuracy: 0.6623\n",
      "Epoch 16/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5688 - accuracy: 0.6618 - val_loss: 0.6117 - val_accuracy: 0.6133\n",
      "Epoch 17/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5615 - accuracy: 0.6683 - val_loss: 0.5912 - val_accuracy: 0.6614\n",
      "Epoch 18/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5587 - accuracy: 0.6675 - val_loss: 0.5764 - val_accuracy: 0.6977\n",
      "Epoch 19/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5452 - accuracy: 0.6868 - val_loss: 0.6495 - val_accuracy: 0.5943\n",
      "Epoch 20/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5466 - accuracy: 0.6795 - val_loss: 0.6002 - val_accuracy: 0.6253\n",
      "Epoch 21/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5404 - accuracy: 0.6898 - val_loss: 0.6110 - val_accuracy: 0.6534\n",
      "Epoch 22/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5381 - accuracy: 0.6907 - val_loss: 0.6256 - val_accuracy: 0.6145\n",
      "Epoch 23/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5176 - accuracy: 0.7044 - val_loss: 0.5632 - val_accuracy: 0.6944\n",
      "Epoch 24/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5183 - accuracy: 0.6980 - val_loss: 0.6544 - val_accuracy: 0.6033\n",
      "Epoch 25/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5110 - accuracy: 0.7083 - val_loss: 0.6925 - val_accuracy: 0.5557\n",
      "Epoch 26/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5013 - accuracy: 0.7281 - val_loss: 0.4575 - val_accuracy: 0.7986\n",
      "Epoch 27/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4897 - accuracy: 0.7251 - val_loss: 0.5125 - val_accuracy: 0.7224\n",
      "Epoch 28/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4832 - accuracy: 0.7350 - val_loss: 0.4617 - val_accuracy: 0.7750\n",
      "Epoch 29/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4660 - accuracy: 0.7442 - val_loss: 0.5583 - val_accuracy: 0.7059\n",
      "Epoch 30/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4745 - accuracy: 0.7457 - val_loss: 0.5529 - val_accuracy: 0.6653\n",
      "Epoch 31/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4615 - accuracy: 0.7467 - val_loss: 0.5601 - val_accuracy: 0.7102\n",
      "Epoch 32/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4487 - accuracy: 0.7585 - val_loss: 0.5024 - val_accuracy: 0.7428\n",
      "Epoch 33/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4330 - accuracy: 0.7677 - val_loss: 0.5375 - val_accuracy: 0.7475\n",
      "Epoch 34/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4225 - accuracy: 0.7707 - val_loss: 0.5558 - val_accuracy: 0.7260\n",
      "Epoch 35/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4174 - accuracy: 0.7765 - val_loss: 0.6021 - val_accuracy: 0.7010\n",
      "Epoch 36/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4080 - accuracy: 0.7835 - val_loss: 0.4978 - val_accuracy: 0.7453\n",
      "Epoch 37/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4036 - accuracy: 0.7813 - val_loss: 0.5293 - val_accuracy: 0.7441\n",
      "Epoch 38/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4021 - accuracy: 0.7903 - val_loss: 0.4100 - val_accuracy: 0.8132\n",
      "Epoch 39/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3875 - accuracy: 0.7985 - val_loss: 0.4748 - val_accuracy: 0.7657\n",
      "Epoch 40/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3744 - accuracy: 0.8029 - val_loss: 0.5063 - val_accuracy: 0.7589\n",
      "Epoch 41/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3719 - accuracy: 0.8042 - val_loss: 0.4820 - val_accuracy: 0.7428\n",
      "Epoch 42/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3591 - accuracy: 0.8157 - val_loss: 0.5531 - val_accuracy: 0.7267\n",
      "Epoch 43/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3651 - accuracy: 0.8094 - val_loss: 0.4304 - val_accuracy: 0.8042\n",
      "Epoch 44/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3575 - accuracy: 0.8155 - val_loss: 0.5834 - val_accuracy: 0.7293\n",
      "Epoch 45/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3411 - accuracy: 0.8262 - val_loss: 0.5353 - val_accuracy: 0.7771\n",
      "Epoch 46/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3383 - accuracy: 0.8239 - val_loss: 0.5525 - val_accuracy: 0.7411\n",
      "Epoch 47/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3276 - accuracy: 0.8362 - val_loss: 0.4918 - val_accuracy: 0.7808\n",
      "Epoch 48/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3188 - accuracy: 0.8408 - val_loss: 0.4957 - val_accuracy: 0.7820\n",
      "Epoch 49/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3055 - accuracy: 0.8459 - val_loss: 0.6360 - val_accuracy: 0.6894\n",
      "Epoch 50/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3159 - accuracy: 0.8397 - val_loss: 0.4924 - val_accuracy: 0.7726\n",
      "Epoch 51/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3133 - accuracy: 0.8430 - val_loss: 0.4563 - val_accuracy: 0.8058\n",
      "Epoch 52/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3020 - accuracy: 0.8548 - val_loss: 0.5284 - val_accuracy: 0.7642\n",
      "Epoch 53/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2942 - accuracy: 0.8537 - val_loss: 0.5158 - val_accuracy: 0.7727\n",
      "Epoch 54/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2839 - accuracy: 0.8571 - val_loss: 0.5487 - val_accuracy: 0.7919\n",
      "Epoch 55/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2812 - accuracy: 0.8600 - val_loss: 0.4907 - val_accuracy: 0.7761\n",
      "Epoch 56/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2790 - accuracy: 0.8621 - val_loss: 0.4903 - val_accuracy: 0.8166\n",
      "Epoch 57/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2700 - accuracy: 0.8668 - val_loss: 0.4817 - val_accuracy: 0.7965\n",
      "Epoch 58/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2601 - accuracy: 0.8748 - val_loss: 0.4858 - val_accuracy: 0.7945\n",
      "Epoch 59/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2571 - accuracy: 0.8743 - val_loss: 0.5185 - val_accuracy: 0.7858\n",
      "Epoch 60/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2506 - accuracy: 0.8805 - val_loss: 0.5694 - val_accuracy: 0.7323\n",
      "Epoch 61/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2507 - accuracy: 0.8818 - val_loss: 0.5459 - val_accuracy: 0.7911\n",
      "Epoch 62/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2511 - accuracy: 0.8785 - val_loss: 0.4770 - val_accuracy: 0.8030\n",
      "Epoch 63/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2385 - accuracy: 0.8863 - val_loss: 0.5866 - val_accuracy: 0.7707\n",
      "Epoch 64/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2410 - accuracy: 0.8826 - val_loss: 0.5185 - val_accuracy: 0.7818\n",
      "Epoch 65/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2327 - accuracy: 0.8884 - val_loss: 0.5561 - val_accuracy: 0.8003\n",
      "Epoch 66/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2093 - accuracy: 0.9045 - val_loss: 0.6268 - val_accuracy: 0.7951\n",
      "Epoch 67/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2209 - accuracy: 0.8976 - val_loss: 0.6163 - val_accuracy: 0.7732\n",
      "Epoch 68/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2200 - accuracy: 0.8972 - val_loss: 0.5281 - val_accuracy: 0.8101\n",
      "Epoch 69/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2038 - accuracy: 0.9061 - val_loss: 0.5208 - val_accuracy: 0.7990\n",
      "Epoch 70/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2025 - accuracy: 0.9059 - val_loss: 0.5294 - val_accuracy: 0.8186\n",
      "Epoch 71/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1863 - accuracy: 0.9166 - val_loss: 0.5324 - val_accuracy: 0.7951\n",
      "Epoch 72/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1923 - accuracy: 0.9105 - val_loss: 0.6548 - val_accuracy: 0.7918\n",
      "Epoch 73/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1889 - accuracy: 0.9147 - val_loss: 0.6029 - val_accuracy: 0.7848\n",
      "Epoch 74/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1850 - accuracy: 0.9152 - val_loss: 0.6429 - val_accuracy: 0.7817\n",
      "Epoch 75/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1919 - accuracy: 0.9088 - val_loss: 0.4944 - val_accuracy: 0.8137\n",
      "Epoch 76/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1875 - accuracy: 0.9180 - val_loss: 0.5168 - val_accuracy: 0.8059\n",
      "Epoch 77/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1774 - accuracy: 0.9223 - val_loss: 0.6548 - val_accuracy: 0.7773\n",
      "Epoch 78/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1654 - accuracy: 0.9273 - val_loss: 0.6019 - val_accuracy: 0.8196\n",
      "Epoch 79/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1665 - accuracy: 0.9257 - val_loss: 0.5313 - val_accuracy: 0.8116\n",
      "Epoch 80/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1625 - accuracy: 0.9278 - val_loss: 0.6057 - val_accuracy: 0.8017\n",
      "415/415 [==============================] - 3s 7ms/step - loss: 0.6297 - accuracy: 0.8006\n",
      "415/415 [==============================] - 2s 5ms/step\n",
      "(13272,)\n",
      "(13272,)\n",
      "{'sn': 0.583413693346191, 'sp': 0.8408644400785854, 'acc': 0.800632894039154, 'MCC': 0.36867857925923236, 'AUC': 0.797248608935023, 'AUPRC': 0.4459339254341888, 'precision': 0.40441176470588236, 'F1': 0.4776944334780892}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharzil/anaconda3/envs/tf214/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "623/623 [==============================] - 15s 19ms/step - loss: 0.6947 - accuracy: 0.5280 - val_loss: 0.6439 - val_accuracy: 0.8195\n",
      "Epoch 2/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6860 - accuracy: 0.5362 - val_loss: 0.6565 - val_accuracy: 0.3872\n",
      "Epoch 3/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6736 - accuracy: 0.4952 - val_loss: 0.7527 - val_accuracy: 0.4027\n",
      "Epoch 4/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6676 - accuracy: 0.5301 - val_loss: 0.5850 - val_accuracy: 0.7176\n",
      "Epoch 5/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6550 - accuracy: 0.5604 - val_loss: 0.7309 - val_accuracy: 0.3853\n",
      "Epoch 6/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6533 - accuracy: 0.5512 - val_loss: 0.6281 - val_accuracy: 0.5546\n",
      "Epoch 7/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6506 - accuracy: 0.5377 - val_loss: 0.6410 - val_accuracy: 0.5703\n",
      "Epoch 8/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6413 - accuracy: 0.5503 - val_loss: 0.6355 - val_accuracy: 0.5683\n",
      "Epoch 9/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6379 - accuracy: 0.5399 - val_loss: 0.6596 - val_accuracy: 0.5101\n",
      "Epoch 10/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6332 - accuracy: 0.5397 - val_loss: 0.7407 - val_accuracy: 0.4414\n",
      "Epoch 11/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6277 - accuracy: 0.5356 - val_loss: 0.7004 - val_accuracy: 0.4846\n",
      "Epoch 12/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6198 - accuracy: 0.5431 - val_loss: 0.5748 - val_accuracy: 0.5727\n",
      "Epoch 13/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6143 - accuracy: 0.5421 - val_loss: 0.5859 - val_accuracy: 0.6069\n",
      "Epoch 14/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6146 - accuracy: 0.5302 - val_loss: 0.5979 - val_accuracy: 0.5662\n",
      "Epoch 15/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6094 - accuracy: 0.5472 - val_loss: 0.6726 - val_accuracy: 0.4745\n",
      "Epoch 16/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6029 - accuracy: 0.5700 - val_loss: 0.6489 - val_accuracy: 0.4589\n",
      "Epoch 17/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5995 - accuracy: 0.5937 - val_loss: 0.6694 - val_accuracy: 0.5443\n",
      "Epoch 18/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5953 - accuracy: 0.6077 - val_loss: 0.4884 - val_accuracy: 0.7793\n",
      "Epoch 19/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5882 - accuracy: 0.6227 - val_loss: 0.5594 - val_accuracy: 0.6290\n",
      "Epoch 20/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5808 - accuracy: 0.6264 - val_loss: 0.5638 - val_accuracy: 0.6503\n",
      "Epoch 21/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5800 - accuracy: 0.6301 - val_loss: 0.5610 - val_accuracy: 0.7071\n",
      "Epoch 22/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5725 - accuracy: 0.6441 - val_loss: 0.5055 - val_accuracy: 0.7588\n",
      "Epoch 23/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5650 - accuracy: 0.6560 - val_loss: 0.5457 - val_accuracy: 0.6895\n",
      "Epoch 24/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5695 - accuracy: 0.6491 - val_loss: 0.4995 - val_accuracy: 0.7497\n",
      "Epoch 25/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5628 - accuracy: 0.6658 - val_loss: 0.5808 - val_accuracy: 0.6769\n",
      "Epoch 26/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5441 - accuracy: 0.6912 - val_loss: 0.5502 - val_accuracy: 0.7107\n",
      "Epoch 27/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5422 - accuracy: 0.6958 - val_loss: 0.4962 - val_accuracy: 0.7512\n",
      "Epoch 28/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5334 - accuracy: 0.6993 - val_loss: 0.5470 - val_accuracy: 0.7323\n",
      "Epoch 29/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5339 - accuracy: 0.6999 - val_loss: 0.5949 - val_accuracy: 0.6630\n",
      "Epoch 30/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5241 - accuracy: 0.7104 - val_loss: 0.5976 - val_accuracy: 0.6898\n",
      "Epoch 31/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5256 - accuracy: 0.6898 - val_loss: 0.4537 - val_accuracy: 0.8021\n",
      "Epoch 32/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5259 - accuracy: 0.6961 - val_loss: 0.5612 - val_accuracy: 0.6879\n",
      "Epoch 33/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4996 - accuracy: 0.7231 - val_loss: 0.4929 - val_accuracy: 0.7583\n",
      "Epoch 34/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5034 - accuracy: 0.7116 - val_loss: 0.4766 - val_accuracy: 0.7685\n",
      "Epoch 35/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4976 - accuracy: 0.7281 - val_loss: 0.4414 - val_accuracy: 0.7891\n",
      "Epoch 36/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4852 - accuracy: 0.7362 - val_loss: 0.5123 - val_accuracy: 0.7377\n",
      "Epoch 37/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4760 - accuracy: 0.7421 - val_loss: 0.7123 - val_accuracy: 0.6033\n",
      "Epoch 38/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4743 - accuracy: 0.7482 - val_loss: 0.4812 - val_accuracy: 0.7648\n",
      "Epoch 39/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4566 - accuracy: 0.7542 - val_loss: 0.5328 - val_accuracy: 0.7221\n",
      "Epoch 40/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4672 - accuracy: 0.7492 - val_loss: 0.5808 - val_accuracy: 0.6658\n",
      "Epoch 41/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4545 - accuracy: 0.7575 - val_loss: 0.5036 - val_accuracy: 0.7498\n",
      "Epoch 42/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4411 - accuracy: 0.7664 - val_loss: 0.5566 - val_accuracy: 0.7027\n",
      "Epoch 43/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4429 - accuracy: 0.7579 - val_loss: 0.4736 - val_accuracy: 0.7808\n",
      "Epoch 44/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4474 - accuracy: 0.7538 - val_loss: 0.6130 - val_accuracy: 0.6552\n",
      "Epoch 45/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4244 - accuracy: 0.7708 - val_loss: 0.4837 - val_accuracy: 0.7720\n",
      "Epoch 46/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4202 - accuracy: 0.7851 - val_loss: 0.5076 - val_accuracy: 0.7470\n",
      "Epoch 47/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4112 - accuracy: 0.7833 - val_loss: 0.4539 - val_accuracy: 0.7925\n",
      "Epoch 48/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4043 - accuracy: 0.7863 - val_loss: 0.4570 - val_accuracy: 0.7771\n",
      "Epoch 49/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4059 - accuracy: 0.7860 - val_loss: 0.5089 - val_accuracy: 0.7293\n",
      "Epoch 50/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3998 - accuracy: 0.7893 - val_loss: 0.4668 - val_accuracy: 0.7827\n",
      "Epoch 51/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3805 - accuracy: 0.8048 - val_loss: 0.6532 - val_accuracy: 0.6706\n",
      "Epoch 52/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3819 - accuracy: 0.8054 - val_loss: 0.4921 - val_accuracy: 0.7574\n",
      "Epoch 53/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3679 - accuracy: 0.8086 - val_loss: 0.5054 - val_accuracy: 0.7524\n",
      "Epoch 54/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3620 - accuracy: 0.8169 - val_loss: 0.6605 - val_accuracy: 0.7109\n",
      "Epoch 55/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3685 - accuracy: 0.8113 - val_loss: 0.4296 - val_accuracy: 0.8020\n",
      "Epoch 56/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3646 - accuracy: 0.8137 - val_loss: 0.4888 - val_accuracy: 0.7710\n",
      "Epoch 57/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3529 - accuracy: 0.8220 - val_loss: 0.4665 - val_accuracy: 0.8074\n",
      "Epoch 58/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3420 - accuracy: 0.8261 - val_loss: 0.5885 - val_accuracy: 0.7474\n",
      "Epoch 59/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3339 - accuracy: 0.8347 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 60/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3428 - accuracy: 0.8255 - val_loss: 0.5316 - val_accuracy: 0.7697\n",
      "Epoch 61/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3450 - accuracy: 0.8213 - val_loss: 0.5044 - val_accuracy: 0.7804\n",
      "Epoch 62/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3253 - accuracy: 0.8372 - val_loss: 0.5678 - val_accuracy: 0.7434\n",
      "Epoch 63/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3158 - accuracy: 0.8390 - val_loss: 0.4582 - val_accuracy: 0.8073\n",
      "Epoch 64/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3066 - accuracy: 0.8468 - val_loss: 0.5065 - val_accuracy: 0.7733\n",
      "Epoch 65/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3129 - accuracy: 0.8419 - val_loss: 0.5088 - val_accuracy: 0.7711\n",
      "Epoch 66/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2985 - accuracy: 0.8507 - val_loss: 0.5624 - val_accuracy: 0.7636\n",
      "Epoch 67/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2955 - accuracy: 0.8532 - val_loss: 0.4743 - val_accuracy: 0.8071\n",
      "Epoch 68/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3043 - accuracy: 0.8489 - val_loss: 0.4565 - val_accuracy: 0.7960\n",
      "Epoch 69/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2843 - accuracy: 0.8608 - val_loss: 0.4908 - val_accuracy: 0.8007\n",
      "Epoch 70/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2722 - accuracy: 0.8661 - val_loss: 0.5079 - val_accuracy: 0.7949\n",
      "Epoch 71/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2726 - accuracy: 0.8619 - val_loss: 0.6012 - val_accuracy: 0.7576\n",
      "Epoch 72/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2705 - accuracy: 0.8682 - val_loss: 0.5982 - val_accuracy: 0.7186\n",
      "Epoch 73/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2726 - accuracy: 0.8691 - val_loss: 0.5031 - val_accuracy: 0.7913\n",
      "Epoch 74/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.2710 - accuracy: 0.8703 - val_loss: 0.5537 - val_accuracy: 0.7609\n",
      "Epoch 75/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2606 - accuracy: 0.8763 - val_loss: 0.4999 - val_accuracy: 0.7967\n",
      "Epoch 76/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.2639 - accuracy: 0.8704 - val_loss: 0.4907 - val_accuracy: 0.8283\n",
      "Epoch 77/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2604 - accuracy: 0.8789 - val_loss: 0.5126 - val_accuracy: 0.7968\n",
      "Epoch 78/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.2491 - accuracy: 0.8844 - val_loss: 0.4795 - val_accuracy: 0.8148\n",
      "Epoch 79/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2437 - accuracy: 0.8821 - val_loss: 0.5984 - val_accuracy: 0.7323\n",
      "Epoch 80/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.2550 - accuracy: 0.8781 - val_loss: 0.5708 - val_accuracy: 0.7655\n",
      "415/415 [==============================] - 3s 7ms/step - loss: 0.5683 - accuracy: 0.7677\n",
      "415/415 [==============================] - 3s 6ms/step\n",
      "(13273,)\n",
      "(13273,)\n",
      "{'sn': 0.6766265060240964, 'sp': 0.7846043936417217, 'acc': 0.7677239775657654, 'MCC': 0.37009805204357704, 'AUC': 0.8058823757254415, 'AUPRC': 0.45337415694527644, 'precision': 0.36792452830188677, 'F1': 0.47665931081310475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharzil/anaconda3/envs/tf214/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "623/623 [==============================] - 15s 19ms/step - loss: 0.6996 - accuracy: 0.5093 - val_loss: 0.6638 - val_accuracy: 0.8437\n",
      "Epoch 2/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.6933 - accuracy: 0.5079 - val_loss: 0.6444 - val_accuracy: 0.8436\n",
      "Epoch 3/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6777 - accuracy: 0.5317 - val_loss: 0.7410 - val_accuracy: 0.4154\n",
      "Epoch 4/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6657 - accuracy: 0.5617 - val_loss: 0.8111 - val_accuracy: 0.4354\n",
      "Epoch 5/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6500 - accuracy: 0.5401 - val_loss: 0.7308 - val_accuracy: 0.5293\n",
      "Epoch 6/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6495 - accuracy: 0.5443 - val_loss: 0.6749 - val_accuracy: 0.4770\n",
      "Epoch 7/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6436 - accuracy: 0.5275 - val_loss: 0.6780 - val_accuracy: 0.4850\n",
      "Epoch 8/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.6304 - accuracy: 0.5593 - val_loss: 0.7480 - val_accuracy: 0.5293\n",
      "Epoch 9/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6250 - accuracy: 0.5489 - val_loss: 0.5865 - val_accuracy: 0.5469\n",
      "Epoch 10/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6222 - accuracy: 0.5589 - val_loss: 0.5088 - val_accuracy: 0.7214\n",
      "Epoch 11/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6222 - accuracy: 0.5486 - val_loss: 0.5492 - val_accuracy: 0.6366\n",
      "Epoch 12/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6151 - accuracy: 0.5472 - val_loss: 0.5724 - val_accuracy: 0.6229\n",
      "Epoch 13/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6132 - accuracy: 0.5508 - val_loss: 0.6698 - val_accuracy: 0.5552\n",
      "Epoch 14/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6095 - accuracy: 0.5498 - val_loss: 0.6687 - val_accuracy: 0.5352\n",
      "Epoch 15/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.6012 - accuracy: 0.5752 - val_loss: 0.5821 - val_accuracy: 0.5874\n",
      "Epoch 16/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5919 - accuracy: 0.5922 - val_loss: 0.6744 - val_accuracy: 0.5433\n",
      "Epoch 17/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.5903 - accuracy: 0.6033 - val_loss: 0.5178 - val_accuracy: 0.7507\n",
      "Epoch 18/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5811 - accuracy: 0.6079 - val_loss: 0.6096 - val_accuracy: 0.6039\n",
      "Epoch 19/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.5749 - accuracy: 0.6334 - val_loss: 0.5301 - val_accuracy: 0.6962\n",
      "Epoch 20/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5594 - accuracy: 0.6474 - val_loss: 0.6229 - val_accuracy: 0.5886\n",
      "Epoch 21/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5688 - accuracy: 0.6413 - val_loss: 0.5952 - val_accuracy: 0.6751\n",
      "Epoch 22/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5518 - accuracy: 0.6614 - val_loss: 0.5964 - val_accuracy: 0.6124\n",
      "Epoch 23/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5326 - accuracy: 0.6820 - val_loss: 0.4981 - val_accuracy: 0.7379\n",
      "Epoch 24/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5293 - accuracy: 0.6891 - val_loss: 0.5867 - val_accuracy: 0.6369\n",
      "Epoch 25/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5240 - accuracy: 0.7005 - val_loss: 0.4539 - val_accuracy: 0.7847\n",
      "Epoch 26/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.5122 - accuracy: 0.7088 - val_loss: 0.4712 - val_accuracy: 0.7707\n",
      "Epoch 27/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.5114 - accuracy: 0.7136 - val_loss: 0.5091 - val_accuracy: 0.7463\n",
      "Epoch 28/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4883 - accuracy: 0.7300 - val_loss: 0.4647 - val_accuracy: 0.7822\n",
      "Epoch 29/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4810 - accuracy: 0.7376 - val_loss: 0.7001 - val_accuracy: 0.6176\n",
      "Epoch 30/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4700 - accuracy: 0.7360 - val_loss: 0.5172 - val_accuracy: 0.7090\n",
      "Epoch 31/80\n",
      "623/623 [==============================] - 12s 19ms/step - loss: 0.4781 - accuracy: 0.7374 - val_loss: 0.6296 - val_accuracy: 0.6401\n",
      "Epoch 32/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4771 - accuracy: 0.7348 - val_loss: 0.4981 - val_accuracy: 0.7156\n",
      "Epoch 33/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.4620 - accuracy: 0.7397 - val_loss: 0.5857 - val_accuracy: 0.6949\n",
      "Epoch 34/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4470 - accuracy: 0.7610 - val_loss: 0.4569 - val_accuracy: 0.7652\n",
      "Epoch 35/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4468 - accuracy: 0.7536 - val_loss: 0.4246 - val_accuracy: 0.8126\n",
      "Epoch 36/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4374 - accuracy: 0.7612 - val_loss: 0.4721 - val_accuracy: 0.7801\n",
      "Epoch 37/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4209 - accuracy: 0.7746 - val_loss: 0.6070 - val_accuracy: 0.7022\n",
      "Epoch 38/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4083 - accuracy: 0.7829 - val_loss: 0.4622 - val_accuracy: 0.7682\n",
      "Epoch 39/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4080 - accuracy: 0.7812 - val_loss: 0.4991 - val_accuracy: 0.7498\n",
      "Epoch 40/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4021 - accuracy: 0.7747 - val_loss: 0.4953 - val_accuracy: 0.7438\n",
      "Epoch 41/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3957 - accuracy: 0.7927 - val_loss: 0.4660 - val_accuracy: 0.7814\n",
      "Epoch 42/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3764 - accuracy: 0.8009 - val_loss: 0.5185 - val_accuracy: 0.7343\n",
      "Epoch 43/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3659 - accuracy: 0.8074 - val_loss: 0.5058 - val_accuracy: 0.7568\n",
      "Epoch 44/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3588 - accuracy: 0.8055 - val_loss: 0.4677 - val_accuracy: 0.7638\n",
      "Epoch 45/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3513 - accuracy: 0.8222 - val_loss: 0.5031 - val_accuracy: 0.7450\n",
      "Epoch 46/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3446 - accuracy: 0.8221 - val_loss: 0.6077 - val_accuracy: 0.7022\n",
      "Epoch 47/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3443 - accuracy: 0.8160 - val_loss: 0.4622 - val_accuracy: 0.7933\n",
      "Epoch 48/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3317 - accuracy: 0.8294 - val_loss: 0.4977 - val_accuracy: 0.7639\n",
      "Epoch 49/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3259 - accuracy: 0.8365 - val_loss: 0.4742 - val_accuracy: 0.7765\n",
      "Epoch 50/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3283 - accuracy: 0.8305 - val_loss: 0.4981 - val_accuracy: 0.7830\n",
      "Epoch 51/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3197 - accuracy: 0.8365 - val_loss: 0.4553 - val_accuracy: 0.7944\n",
      "Epoch 52/80\n",
      "623/623 [==============================] - 12s 18ms/step - loss: 0.3046 - accuracy: 0.8446 - val_loss: 0.5448 - val_accuracy: 0.7539\n",
      "Epoch 53/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3027 - accuracy: 0.8492 - val_loss: 0.5369 - val_accuracy: 0.7683\n",
      "Epoch 54/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2974 - accuracy: 0.8505 - val_loss: 0.5745 - val_accuracy: 0.7305\n",
      "Epoch 55/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.3051 - accuracy: 0.8464 - val_loss: 0.4792 - val_accuracy: 0.8311\n",
      "Epoch 56/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2781 - accuracy: 0.8625 - val_loss: 0.6148 - val_accuracy: 0.7441\n",
      "Epoch 57/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2702 - accuracy: 0.8677 - val_loss: 0.4922 - val_accuracy: 0.7881\n",
      "Epoch 58/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2670 - accuracy: 0.8687 - val_loss: 0.5376 - val_accuracy: 0.7826\n",
      "Epoch 59/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2675 - accuracy: 0.8695 - val_loss: 0.5023 - val_accuracy: 0.8052\n",
      "Epoch 60/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2608 - accuracy: 0.8722 - val_loss: 0.5599 - val_accuracy: 0.7707\n",
      "Epoch 61/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2523 - accuracy: 0.8782 - val_loss: 0.5418 - val_accuracy: 0.7962\n",
      "Epoch 62/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2508 - accuracy: 0.8801 - val_loss: 0.4810 - val_accuracy: 0.8242\n",
      "Epoch 63/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2347 - accuracy: 0.8864 - val_loss: 0.5488 - val_accuracy: 0.7879\n",
      "Epoch 64/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2372 - accuracy: 0.8865 - val_loss: 0.4919 - val_accuracy: 0.7995\n",
      "Epoch 65/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2434 - accuracy: 0.8840 - val_loss: 0.5162 - val_accuracy: 0.8201\n",
      "Epoch 66/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2260 - accuracy: 0.8945 - val_loss: 0.5458 - val_accuracy: 0.8032\n",
      "Epoch 67/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2297 - accuracy: 0.8903 - val_loss: 0.5068 - val_accuracy: 0.8064\n",
      "Epoch 68/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2259 - accuracy: 0.8957 - val_loss: 0.6166 - val_accuracy: 0.7838\n",
      "Epoch 69/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2110 - accuracy: 0.9028 - val_loss: 0.5159 - val_accuracy: 0.7971\n",
      "Epoch 70/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2220 - accuracy: 0.8960 - val_loss: 0.5150 - val_accuracy: 0.7789\n",
      "Epoch 71/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2222 - accuracy: 0.8979 - val_loss: 0.5284 - val_accuracy: 0.8214\n",
      "Epoch 72/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2042 - accuracy: 0.9048 - val_loss: 0.5019 - val_accuracy: 0.8244\n",
      "Epoch 73/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1925 - accuracy: 0.9085 - val_loss: 0.6017 - val_accuracy: 0.8034\n",
      "Epoch 74/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1865 - accuracy: 0.9135 - val_loss: 0.5255 - val_accuracy: 0.8072\n",
      "Epoch 75/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1809 - accuracy: 0.9206 - val_loss: 0.5961 - val_accuracy: 0.8270\n",
      "Epoch 76/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1837 - accuracy: 0.9145 - val_loss: 0.5221 - val_accuracy: 0.8183\n",
      "Epoch 77/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1892 - accuracy: 0.9143 - val_loss: 0.5458 - val_accuracy: 0.8298\n",
      "Epoch 78/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1714 - accuracy: 0.9239 - val_loss: 0.5849 - val_accuracy: 0.8134\n",
      "Epoch 79/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1728 - accuracy: 0.9200 - val_loss: 0.5997 - val_accuracy: 0.8214\n",
      "Epoch 80/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.1762 - accuracy: 0.9231 - val_loss: 0.6016 - val_accuracy: 0.8203\n",
      "415/415 [==============================] - 3s 6ms/step - loss: 0.5804 - accuracy: 0.8196\n",
      "415/415 [==============================] - 2s 5ms/step\n",
      "(13274,)\n",
      "(13274,)\n",
      "{'sn': 0.5840963855421687, 'sp': 0.8632020716135369, 'acc': 0.8195720911026001, 'MCC': 0.40113433224212014, 'AUC': 0.8272100671639141, 'AUPRC': 0.4862822324434701, 'precision': 0.44169096209912534, 'F1': 0.5030089230130732}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharzil/anaconda3/envs/tf214/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "623/623 [==============================] - 14s 18ms/step - loss: 0.6954 - accuracy: 0.5076 - val_loss: 0.7651 - val_accuracy: 0.2718\n",
      "Epoch 2/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6850 - accuracy: 0.4545 - val_loss: 0.6294 - val_accuracy: 0.8425\n",
      "Epoch 3/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6805 - accuracy: 0.4608 - val_loss: 0.6780 - val_accuracy: 0.5424\n",
      "Epoch 4/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6601 - accuracy: 0.5373 - val_loss: 0.6126 - val_accuracy: 0.5530\n",
      "Epoch 5/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6496 - accuracy: 0.5292 - val_loss: 0.7584 - val_accuracy: 0.4011\n",
      "Epoch 6/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6412 - accuracy: 0.5370 - val_loss: 0.6741 - val_accuracy: 0.4668\n",
      "Epoch 7/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6317 - accuracy: 0.5431 - val_loss: 0.7359 - val_accuracy: 0.4085\n",
      "Epoch 8/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6243 - accuracy: 0.5460 - val_loss: 0.7111 - val_accuracy: 0.4986\n",
      "Epoch 9/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6155 - accuracy: 0.5470 - val_loss: 0.6080 - val_accuracy: 0.5074\n",
      "Epoch 10/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6118 - accuracy: 0.5681 - val_loss: 0.7073 - val_accuracy: 0.4537\n",
      "Epoch 11/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.6044 - accuracy: 0.5920 - val_loss: 0.6343 - val_accuracy: 0.5742\n",
      "Epoch 12/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5889 - accuracy: 0.6329 - val_loss: 0.6587 - val_accuracy: 0.5727\n",
      "Epoch 13/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5906 - accuracy: 0.6279 - val_loss: 0.5592 - val_accuracy: 0.7137\n",
      "Epoch 14/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5861 - accuracy: 0.6430 - val_loss: 0.5750 - val_accuracy: 0.6442\n",
      "Epoch 15/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5802 - accuracy: 0.6334 - val_loss: 0.4966 - val_accuracy: 0.7390\n",
      "Epoch 16/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5689 - accuracy: 0.6459 - val_loss: 0.7189 - val_accuracy: 0.5376\n",
      "Epoch 17/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5606 - accuracy: 0.6571 - val_loss: 0.5055 - val_accuracy: 0.7674\n",
      "Epoch 18/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5618 - accuracy: 0.6581 - val_loss: 0.5833 - val_accuracy: 0.6146\n",
      "Epoch 19/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5465 - accuracy: 0.6851 - val_loss: 0.5047 - val_accuracy: 0.7337\n",
      "Epoch 20/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5374 - accuracy: 0.6829 - val_loss: 0.5930 - val_accuracy: 0.6184\n",
      "Epoch 21/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5350 - accuracy: 0.6907 - val_loss: 0.5119 - val_accuracy: 0.7314\n",
      "Epoch 22/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5236 - accuracy: 0.6925 - val_loss: 0.6651 - val_accuracy: 0.6054\n",
      "Epoch 23/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5189 - accuracy: 0.6960 - val_loss: 0.6726 - val_accuracy: 0.5829\n",
      "Epoch 24/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5120 - accuracy: 0.7074 - val_loss: 0.5539 - val_accuracy: 0.6888\n",
      "Epoch 25/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.5061 - accuracy: 0.7089 - val_loss: 0.6262 - val_accuracy: 0.6539\n",
      "Epoch 26/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4872 - accuracy: 0.7353 - val_loss: 0.6702 - val_accuracy: 0.5906\n",
      "Epoch 27/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4933 - accuracy: 0.7196 - val_loss: 0.4767 - val_accuracy: 0.7440\n",
      "Epoch 28/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4792 - accuracy: 0.7319 - val_loss: 0.6135 - val_accuracy: 0.6064\n",
      "Epoch 29/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4703 - accuracy: 0.7442 - val_loss: 0.5616 - val_accuracy: 0.6990\n",
      "Epoch 30/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4703 - accuracy: 0.7396 - val_loss: 0.5290 - val_accuracy: 0.7079\n",
      "Epoch 31/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4460 - accuracy: 0.7558 - val_loss: 0.5558 - val_accuracy: 0.6789\n",
      "Epoch 32/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4513 - accuracy: 0.7512 - val_loss: 0.4837 - val_accuracy: 0.7565\n",
      "Epoch 33/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4315 - accuracy: 0.7574 - val_loss: 0.5317 - val_accuracy: 0.7089\n",
      "Epoch 34/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.4296 - accuracy: 0.7651 - val_loss: 0.6016 - val_accuracy: 0.6798\n",
      "Epoch 35/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.4185 - accuracy: 0.7667 - val_loss: 0.5213 - val_accuracy: 0.7095\n",
      "Epoch 36/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.4189 - accuracy: 0.7700 - val_loss: 0.5240 - val_accuracy: 0.7070\n",
      "Epoch 37/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.4084 - accuracy: 0.7862 - val_loss: 0.5692 - val_accuracy: 0.7106\n",
      "Epoch 38/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4070 - accuracy: 0.7813 - val_loss: 0.4796 - val_accuracy: 0.7674\n",
      "Epoch 39/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3998 - accuracy: 0.7869 - val_loss: 0.5427 - val_accuracy: 0.7065\n",
      "Epoch 40/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3984 - accuracy: 0.7858 - val_loss: 0.5577 - val_accuracy: 0.7243\n",
      "Epoch 41/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3812 - accuracy: 0.7942 - val_loss: 0.5754 - val_accuracy: 0.7103\n",
      "Epoch 42/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3664 - accuracy: 0.8080 - val_loss: 0.5617 - val_accuracy: 0.7336\n",
      "Epoch 43/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3668 - accuracy: 0.8046 - val_loss: 0.6270 - val_accuracy: 0.7069\n",
      "Epoch 44/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3564 - accuracy: 0.8104 - val_loss: 0.4738 - val_accuracy: 0.7421\n",
      "Epoch 45/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3577 - accuracy: 0.8163 - val_loss: 0.5066 - val_accuracy: 0.7683\n",
      "Epoch 46/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3419 - accuracy: 0.8283 - val_loss: 0.4431 - val_accuracy: 0.7988\n",
      "Epoch 47/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3418 - accuracy: 0.8248 - val_loss: 0.4540 - val_accuracy: 0.7920\n",
      "Epoch 48/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3288 - accuracy: 0.8340 - val_loss: 0.5337 - val_accuracy: 0.7702\n",
      "Epoch 49/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3299 - accuracy: 0.8358 - val_loss: 0.4785 - val_accuracy: 0.8001\n",
      "Epoch 50/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3196 - accuracy: 0.8373 - val_loss: 0.4932 - val_accuracy: 0.7808\n",
      "Epoch 51/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3231 - accuracy: 0.8358 - val_loss: 0.5489 - val_accuracy: 0.7662\n",
      "Epoch 52/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3061 - accuracy: 0.8451 - val_loss: 0.5158 - val_accuracy: 0.7980\n",
      "Epoch 53/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2991 - accuracy: 0.8478 - val_loss: 0.5043 - val_accuracy: 0.7772\n",
      "Epoch 54/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2968 - accuracy: 0.8532 - val_loss: 0.5887 - val_accuracy: 0.7463\n",
      "Epoch 55/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3126 - accuracy: 0.8432 - val_loss: 0.5491 - val_accuracy: 0.7560\n",
      "Epoch 56/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2990 - accuracy: 0.8489 - val_loss: 0.6225 - val_accuracy: 0.6813\n",
      "Epoch 57/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2833 - accuracy: 0.8576 - val_loss: 0.5575 - val_accuracy: 0.7787\n",
      "Epoch 58/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2893 - accuracy: 0.8571 - val_loss: 0.5295 - val_accuracy: 0.7650\n",
      "Epoch 59/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2812 - accuracy: 0.8626 - val_loss: 0.5566 - val_accuracy: 0.7947\n",
      "Epoch 60/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2734 - accuracy: 0.8656 - val_loss: 0.5806 - val_accuracy: 0.7309\n",
      "Epoch 61/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2557 - accuracy: 0.8769 - val_loss: 0.5971 - val_accuracy: 0.7849\n",
      "Epoch 62/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2621 - accuracy: 0.8732 - val_loss: 0.6495 - val_accuracy: 0.7181\n",
      "Epoch 63/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2802 - accuracy: 0.8608 - val_loss: 0.5899 - val_accuracy: 0.7756\n",
      "Epoch 64/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2566 - accuracy: 0.8782 - val_loss: 0.6329 - val_accuracy: 0.7152\n",
      "Epoch 65/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2553 - accuracy: 0.8772 - val_loss: 0.5357 - val_accuracy: 0.7954\n",
      "Epoch 66/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2386 - accuracy: 0.8871 - val_loss: 0.6139 - val_accuracy: 0.7784\n",
      "Epoch 67/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.2464 - accuracy: 0.8784 - val_loss: 0.5900 - val_accuracy: 0.7403\n",
      "Epoch 68/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2367 - accuracy: 0.8911 - val_loss: 0.5589 - val_accuracy: 0.8080\n",
      "Epoch 69/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2251 - accuracy: 0.8926 - val_loss: 0.5395 - val_accuracy: 0.7893\n",
      "Epoch 70/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2298 - accuracy: 0.8920 - val_loss: 0.5966 - val_accuracy: 0.7983\n",
      "Epoch 71/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2522 - accuracy: 0.8844 - val_loss: 0.6088 - val_accuracy: 0.7983\n",
      "Epoch 72/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2425 - accuracy: 0.8782 - val_loss: 0.5595 - val_accuracy: 0.7719\n",
      "Epoch 73/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2198 - accuracy: 0.8983 - val_loss: 0.6116 - val_accuracy: 0.7466\n",
      "Epoch 74/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2236 - accuracy: 0.9004 - val_loss: 0.5742 - val_accuracy: 0.7830\n",
      "Epoch 75/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2224 - accuracy: 0.9022 - val_loss: 0.5037 - val_accuracy: 0.8048\n",
      "Epoch 76/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2137 - accuracy: 0.9023 - val_loss: 0.6486 - val_accuracy: 0.7631\n",
      "Epoch 77/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2110 - accuracy: 0.9035 - val_loss: 0.6103 - val_accuracy: 0.8119\n",
      "Epoch 78/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2032 - accuracy: 0.9067 - val_loss: 0.6269 - val_accuracy: 0.7974\n",
      "Epoch 79/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2022 - accuracy: 0.9074 - val_loss: 0.5619 - val_accuracy: 0.8111\n",
      "Epoch 80/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1954 - accuracy: 0.9140 - val_loss: 0.5966 - val_accuracy: 0.8062\n",
      "415/415 [==============================] - 3s 6ms/step - loss: 0.6246 - accuracy: 0.7978\n",
      "415/415 [==============================] - 2s 5ms/step\n",
      "(13273,)\n",
      "(13273,)\n",
      "{'sn': 0.5026506024096385, 'sp': 0.8524736560100018, 'acc': 0.7977849841117859, 'MCC': 0.3206110274111695, 'AUC': 0.7775072786233342, 'AUPRC': 0.422742531720095, 'precision': 0.38701298701298703, 'F1': 0.4373165618448637}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharzil/anaconda3/envs/tf214/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "623/623 [==============================] - 14s 18ms/step - loss: 0.6956 - accuracy: 0.5151 - val_loss: 0.6480 - val_accuracy: 0.7261\n",
      "Epoch 2/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6775 - accuracy: 0.4913 - val_loss: 0.6185 - val_accuracy: 0.5424\n",
      "Epoch 3/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6688 - accuracy: 0.5128 - val_loss: 0.7582 - val_accuracy: 0.3142\n",
      "Epoch 4/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6614 - accuracy: 0.5229 - val_loss: 0.6051 - val_accuracy: 0.5820\n",
      "Epoch 5/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6556 - accuracy: 0.5021 - val_loss: 0.7587 - val_accuracy: 0.3579\n",
      "Epoch 6/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6448 - accuracy: 0.5448 - val_loss: 0.7377 - val_accuracy: 0.4118\n",
      "Epoch 7/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6372 - accuracy: 0.5299 - val_loss: 0.5511 - val_accuracy: 0.5992\n",
      "Epoch 8/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6403 - accuracy: 0.5086 - val_loss: 0.5843 - val_accuracy: 0.5691\n",
      "Epoch 9/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6295 - accuracy: 0.5353 - val_loss: 0.5215 - val_accuracy: 0.6698\n",
      "Epoch 10/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6335 - accuracy: 0.5347 - val_loss: 0.6246 - val_accuracy: 0.5641\n",
      "Epoch 11/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6204 - accuracy: 0.5599 - val_loss: 0.5361 - val_accuracy: 0.6276\n",
      "Epoch 12/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6134 - accuracy: 0.5537 - val_loss: 0.5609 - val_accuracy: 0.6556\n",
      "Epoch 13/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.6021 - accuracy: 0.5665 - val_loss: 0.6285 - val_accuracy: 0.5762\n",
      "Epoch 14/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5925 - accuracy: 0.6109 - val_loss: 0.5136 - val_accuracy: 0.7158\n",
      "Epoch 15/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5981 - accuracy: 0.5892 - val_loss: 0.5514 - val_accuracy: 0.7362\n",
      "Epoch 16/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5903 - accuracy: 0.6161 - val_loss: 0.5734 - val_accuracy: 0.6418\n",
      "Epoch 17/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.5931 - accuracy: 0.6035 - val_loss: 0.6168 - val_accuracy: 0.6088\n",
      "Epoch 18/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5680 - accuracy: 0.6564 - val_loss: 0.5294 - val_accuracy: 0.7459\n",
      "Epoch 19/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5650 - accuracy: 0.6643 - val_loss: 0.5707 - val_accuracy: 0.6907\n",
      "Epoch 20/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5634 - accuracy: 0.6671 - val_loss: 0.4939 - val_accuracy: 0.7813\n",
      "Epoch 21/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5487 - accuracy: 0.6816 - val_loss: 0.5317 - val_accuracy: 0.7284\n",
      "Epoch 22/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5430 - accuracy: 0.6886 - val_loss: 0.5552 - val_accuracy: 0.6911\n",
      "Epoch 23/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5292 - accuracy: 0.7086 - val_loss: 0.5872 - val_accuracy: 0.6731\n",
      "Epoch 24/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5240 - accuracy: 0.7076 - val_loss: 0.4861 - val_accuracy: 0.7813\n",
      "Epoch 25/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.5194 - accuracy: 0.7018 - val_loss: 0.6139 - val_accuracy: 0.6757\n",
      "Epoch 26/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.5069 - accuracy: 0.7231 - val_loss: 0.6437 - val_accuracy: 0.6196\n",
      "Epoch 27/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4965 - accuracy: 0.7263 - val_loss: 0.4614 - val_accuracy: 0.7868\n",
      "Epoch 28/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4826 - accuracy: 0.7325 - val_loss: 0.5438 - val_accuracy: 0.7021\n",
      "Epoch 29/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.4873 - accuracy: 0.7384 - val_loss: 0.5929 - val_accuracy: 0.7121\n",
      "Epoch 30/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.4598 - accuracy: 0.7575 - val_loss: 0.6299 - val_accuracy: 0.6766\n",
      "Epoch 31/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4668 - accuracy: 0.7474 - val_loss: 0.5880 - val_accuracy: 0.6752\n",
      "Epoch 32/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4473 - accuracy: 0.7697 - val_loss: 0.5421 - val_accuracy: 0.6844\n",
      "Epoch 33/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4414 - accuracy: 0.7681 - val_loss: 0.5452 - val_accuracy: 0.6890\n",
      "Epoch 34/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4345 - accuracy: 0.7642 - val_loss: 0.5373 - val_accuracy: 0.7262\n",
      "Epoch 35/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4380 - accuracy: 0.7662 - val_loss: 0.7086 - val_accuracy: 0.6113\n",
      "Epoch 36/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4217 - accuracy: 0.7775 - val_loss: 0.5277 - val_accuracy: 0.7506\n",
      "Epoch 37/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.4149 - accuracy: 0.7842 - val_loss: 0.4949 - val_accuracy: 0.7733\n",
      "Epoch 38/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3942 - accuracy: 0.7979 - val_loss: 0.5857 - val_accuracy: 0.6854\n",
      "Epoch 39/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3877 - accuracy: 0.7987 - val_loss: 0.5351 - val_accuracy: 0.7494\n",
      "Epoch 40/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3814 - accuracy: 0.8053 - val_loss: 0.5853 - val_accuracy: 0.7135\n",
      "Epoch 41/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3684 - accuracy: 0.8112 - val_loss: 0.4969 - val_accuracy: 0.8038\n",
      "Epoch 42/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3698 - accuracy: 0.8139 - val_loss: 0.4056 - val_accuracy: 0.8341\n",
      "Epoch 43/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3786 - accuracy: 0.8069 - val_loss: 0.5585 - val_accuracy: 0.7354\n",
      "Epoch 44/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3534 - accuracy: 0.8270 - val_loss: 0.4447 - val_accuracy: 0.7936\n",
      "Epoch 45/80\n",
      "623/623 [==============================] - 10s 16ms/step - loss: 0.3379 - accuracy: 0.8302 - val_loss: 0.5032 - val_accuracy: 0.7709\n",
      "Epoch 46/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3520 - accuracy: 0.8185 - val_loss: 0.4545 - val_accuracy: 0.7994\n",
      "Epoch 47/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3228 - accuracy: 0.8413 - val_loss: 0.4961 - val_accuracy: 0.7843\n",
      "Epoch 48/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3258 - accuracy: 0.8333 - val_loss: 0.4665 - val_accuracy: 0.8064\n",
      "Epoch 49/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3105 - accuracy: 0.8465 - val_loss: 0.4618 - val_accuracy: 0.7987\n",
      "Epoch 50/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3012 - accuracy: 0.8480 - val_loss: 0.5035 - val_accuracy: 0.7549\n",
      "Epoch 51/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3001 - accuracy: 0.8495 - val_loss: 0.5711 - val_accuracy: 0.7394\n",
      "Epoch 52/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.3064 - accuracy: 0.8495 - val_loss: 0.4759 - val_accuracy: 0.7967\n",
      "Epoch 53/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3015 - accuracy: 0.8484 - val_loss: 0.5034 - val_accuracy: 0.7887\n",
      "Epoch 54/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.3019 - accuracy: 0.8459 - val_loss: 0.5363 - val_accuracy: 0.7766\n",
      "Epoch 55/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2702 - accuracy: 0.8712 - val_loss: 0.5308 - val_accuracy: 0.7837\n",
      "Epoch 56/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2756 - accuracy: 0.8689 - val_loss: 0.4971 - val_accuracy: 0.7847\n",
      "Epoch 57/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2564 - accuracy: 0.8760 - val_loss: 0.5861 - val_accuracy: 0.7408\n",
      "Epoch 58/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2500 - accuracy: 0.8783 - val_loss: 0.5710 - val_accuracy: 0.8053\n",
      "Epoch 59/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2426 - accuracy: 0.8836 - val_loss: 0.5077 - val_accuracy: 0.8001\n",
      "Epoch 60/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2506 - accuracy: 0.8801 - val_loss: 0.6219 - val_accuracy: 0.7620\n",
      "Epoch 61/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2325 - accuracy: 0.8905 - val_loss: 0.4969 - val_accuracy: 0.8226\n",
      "Epoch 62/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2304 - accuracy: 0.8919 - val_loss: 0.4910 - val_accuracy: 0.8135\n",
      "Epoch 63/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2231 - accuracy: 0.8981 - val_loss: 0.5597 - val_accuracy: 0.7816\n",
      "Epoch 64/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2149 - accuracy: 0.9007 - val_loss: 0.5398 - val_accuracy: 0.8160\n",
      "Epoch 65/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2054 - accuracy: 0.9058 - val_loss: 0.5891 - val_accuracy: 0.8059\n",
      "Epoch 66/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.2152 - accuracy: 0.8996 - val_loss: 0.5993 - val_accuracy: 0.8012\n",
      "Epoch 67/80\n",
      "623/623 [==============================] - 11s 18ms/step - loss: 0.2081 - accuracy: 0.9031 - val_loss: 0.4912 - val_accuracy: 0.8182\n",
      "Epoch 68/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.2037 - accuracy: 0.9053 - val_loss: 0.5904 - val_accuracy: 0.7763\n",
      "Epoch 69/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1982 - accuracy: 0.9079 - val_loss: 0.5880 - val_accuracy: 0.7914\n",
      "Epoch 70/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.1993 - accuracy: 0.9094 - val_loss: 0.5624 - val_accuracy: 0.8052\n",
      "Epoch 71/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1910 - accuracy: 0.9117 - val_loss: 0.5393 - val_accuracy: 0.7941\n",
      "Epoch 72/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1975 - accuracy: 0.9125 - val_loss: 0.6158 - val_accuracy: 0.8009\n",
      "Epoch 73/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1814 - accuracy: 0.9185 - val_loss: 0.5804 - val_accuracy: 0.8036\n",
      "Epoch 74/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1852 - accuracy: 0.9167 - val_loss: 0.5264 - val_accuracy: 0.8297\n",
      "Epoch 75/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.1731 - accuracy: 0.9235 - val_loss: 0.7263 - val_accuracy: 0.7565\n",
      "Epoch 76/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1867 - accuracy: 0.9162 - val_loss: 0.6636 - val_accuracy: 0.7920\n",
      "Epoch 77/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.1736 - accuracy: 0.9227 - val_loss: 0.6855 - val_accuracy: 0.8021\n",
      "Epoch 78/80\n",
      "623/623 [==============================] - 10s 17ms/step - loss: 0.1766 - accuracy: 0.9213 - val_loss: 0.5409 - val_accuracy: 0.8200\n",
      "Epoch 79/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1602 - accuracy: 0.9294 - val_loss: 0.5362 - val_accuracy: 0.8087\n",
      "Epoch 80/80\n",
      "623/623 [==============================] - 11s 17ms/step - loss: 0.1616 - accuracy: 0.9296 - val_loss: 0.6120 - val_accuracy: 0.8259\n",
      "415/415 [==============================] - 3s 6ms/step - loss: 0.6056 - accuracy: 0.8252\n",
      "415/415 [==============================] - 2s 5ms/step\n",
      "(13274,)\n",
      "(13274,)\n",
      "{'sn': 0.49012048192771085, 'sp': 0.887311367086347, 'acc': 0.8252222537994385, 'MCC': 0.3634690518410081, 'AUC': 0.8084950786268568, 'AUPRC': 0.4422135303026697, 'precision': 0.44624835454146555, 'F1': 0.467156637574644}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharzil/anaconda3/envs/tf214/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "folds =5    \n",
    "# random.shuffle(Positive_X);\n",
    "\n",
    "# random.shuffle(Negitive_X);\n",
    "positive_train_1,positive_train_2,positive_train_3=shuffleData(positive_train_1,positive_train_2,positive_train_3);\n",
    "negative_train_1,negative_train_2,negative_train_3=shuffleData(negative_train_1,negative_train_2,negative_train_3);\n",
    "\n",
    "\n",
    "Positive_X_1_Slices = chunkIt(positive_train_1, folds);\n",
    "Positive_X_2_Slices = chunkIt(positive_train_2, folds);\n",
    "Positive_X_3_Slices = chunkIt(positive_train_3, folds);\n",
    "Positive_y_Slices = chunkIt(positive_train_label, folds);\n",
    "\n",
    "Negative_X_1_Slices = chunkIt(negative_train_1, folds);\n",
    "Negative_X_2_Slices = chunkIt(negative_train_2, folds);\n",
    "Negative_X_3_Slices = chunkIt(negative_train_3, folds);\n",
    "Negative_y_Slices = chunkIt(negative_train_label, folds);\n",
    "\n",
    "\n",
    "testing_result = []\n",
    "\n",
    "for test_index in range(folds):\n",
    "\n",
    "    test_X_1 = np.concatenate((Positive_X_1_Slices[test_index],Negative_X_1_Slices[test_index]))\n",
    "    test_X_2 = np.concatenate((Positive_X_2_Slices[test_index],Negative_X_2_Slices[test_index]))\n",
    "    test_X_3 = np.concatenate((Positive_X_3_Slices[test_index],Negative_X_3_Slices[test_index]))    \n",
    "    test_y = np.concatenate((Positive_y_Slices[test_index],Negative_y_Slices[test_index]))\n",
    "\n",
    "    validation_index = (test_index+1) % folds;\n",
    "\n",
    "    valid_X_1 = np.concatenate((Positive_X_1_Slices[validation_index],Negative_X_1_Slices[validation_index]))\n",
    "    valid_X_2 = np.concatenate((Positive_X_2_Slices[validation_index],Negative_X_2_Slices[validation_index]))\n",
    "    valid_X_3 = np.concatenate((Positive_X_3_Slices[validation_index],Negative_X_3_Slices[validation_index]))\n",
    "    \n",
    "    valid_y = np.concatenate((Positive_y_Slices[validation_index],Negative_y_Slices[validation_index]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    start = 0;\n",
    "\n",
    "    for val in range(0, folds):\n",
    "        if val != test_index and val != validation_index:\n",
    "            start = val;\n",
    "            break;\n",
    "\n",
    "    train_X_1 = np.concatenate((Positive_X_1_Slices[start],Negative_X_1_Slices[start]))\n",
    "    train_X_2 = np.concatenate((Positive_X_2_Slices[start],Negative_X_2_Slices[start]))\n",
    "    train_X_3 = np.concatenate((Positive_X_3_Slices[start],Negative_X_3_Slices[start]))\n",
    "    train_y = np.concatenate((Positive_y_Slices[start],Negative_y_Slices[start]))\n",
    "\n",
    "    for i in range(0, folds):\n",
    "        if i != test_index and i != validation_index and i != start:\n",
    "            tempX_1 = np.concatenate((Positive_X_1_Slices[i],Negative_X_1_Slices[i]))\n",
    "            tempX_2 = np.concatenate((Positive_X_2_Slices[i],Negative_X_2_Slices[i]))\n",
    "            tempX_3 = np.concatenate((Positive_X_3_Slices[i],Negative_X_3_Slices[i]))\n",
    "            tempy = np.concatenate((Positive_y_Slices[i],Negative_y_Slices[i]))\n",
    "\n",
    "\n",
    "            train_X_1 = np.concatenate((train_X_1, tempX_1))\n",
    "            train_X_2 = np.concatenate((train_X_2, tempX_2))\n",
    "            train_X_3 = np.concatenate((train_X_3, tempX_3))\n",
    "            train_y = np.concatenate((train_y, tempy))\n",
    "            \n",
    "\n",
    "    test_X_1,test_X_2,test_X_3,test_y = shuffleData2(test_X_1,test_X_2,test_X_3,test_y);\n",
    "    valid_X_1,valid_X_2,valid_X_3,valid_y = shuffleData2(valid_X_1,valid_X_2,valid_X_3,valid_y)\n",
    "    train_X_1,train_X_2,train_X_3,train_y = shuffleData2(train_X_1,train_X_2,train_X_3,train_y);\n",
    "    \n",
    " \n",
    "    model = model_cnn(w_size);\n",
    "    \n",
    "    class_weights = compute_class_weight(class_weight = \"balanced\",classes = np.unique(train_y),y = train_y)\n",
    "    \n",
    "    class_weights = dict(enumerate(class_weights))      \n",
    "    \n",
    "\n",
    "    history = model.fit([train_X_1,train_X_2,train_X_3], train_y, batch_size = 64, class_weight=class_weights,epochs=80, validation_data = ([valid_X_1,valid_X_2,valid_X_3], valid_y));\n",
    "    print(calculateScore(test_X_1,test_X_2,test_X_3, test_y, model, 1))\n",
    "    model.save('my_model'+ str(test_index) +'.h5')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b365d49b-15b9-4065-abf9-3b3d5a4471ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=pickle.load(open(f'./descriptor/in_x_pssm_{w_size}.dat',\"rb\"))\n",
    "test_2=pickle.load(open(f'./descriptor/in_x_dssp_{w_size}.dat',\"rb\"))\n",
    "test_3=pickle.load(open(f'./descriptor/in_x_hmm_{w_size}.dat',\"rb\"))\n",
    "test_label=pickle.load(open(f'./descriptor/in_y_{w_size}.dat',\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4fdd7cf-5560-4a1b-9690-d0d3fedc9246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 14:07:33.072049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8902\n",
      "2024-02-27 14:07:33.730509: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-02-27 14:07:33.890206: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/411 [==============================] - 6s 7ms/step - loss: 0.4772 - accuracy: 0.7880\n",
      "411/411 [==============================] - 2s 5ms/step\n",
      "(13144,)\n",
      "(13144,)\n",
      "{'sn': 0.6, 'sp': 0.8232902701237691, 'acc': 0.7880401611328125, 'MCC': 0.35958368044429523, 'AUC': 0.7842479648470112, 'AUPRC': 0.46693236111056585, 'precision': 0.3889409559512652, 'F1': 0.47194844579226686}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_model = tf.keras.models.load_model('model_19.h5')\n",
    "\n",
    "print(calculateScore(test_1,test_2,test_3, test_label, new_model, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa4693-19c1-4957-9a83-294ed9b52ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
